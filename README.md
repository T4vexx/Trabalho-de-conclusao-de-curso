# Estudo e Compara√ß√£o de Modelos de L√≠ngua para Detec√ß√£o de Fake News em Portugu√™s üïµÔ∏è‚Äç‚ôÇÔ∏èüì∞

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Status](https://img.shields.io/badge/Status-Conclu√≠do-success)
![Institution](https://img.shields.io/badge/UNESP-IBILCE-red)

Reposit√≥rio oficial do Trabalho de Conclus√£o de Curso (TCC) apresentado ao curso de Bacharelado em Ci√™ncia da Computa√ß√£o da **UNESP - S√£o Jos√© do Rio Preto**.

**Autor:** Ot√°vio Augusto Teixeira  
**Orientador:** Prof. Dr. Lucas Correia Ribas  
**Ano:** 2025

## üìÑ Resumo do Projeto

A dissemina√ß√£o de not√≠cias falsas (*fake news*) √© um dos maiores desafios da era digital. Este projeto prop√¥s um estudo comparativo extensivo de diferentes t√©cnicas de Processamento de Linguagem Natural (PLN) para a classifica√ß√£o autom√°tica de not√≠cias em portugu√™s.

O estudo avaliou desde m√©todos estat√≠sticos cl√°ssicos at√© os mais modernos **Grandes Modelos de Linguagem (LLMs)**, analisando qual representa√ß√£o vetorial (embedding) oferece o melhor desempenho na distin√ß√£o entre not√≠cias verdadeiras e falsas.

## üõ†Ô∏è Tecnologias e Modelos Utilizados

O projeto comparou 12 abordagens de representa√ß√£o de texto combinadas com 3 classificadores (SVM, Random Forest, Logistic Regression).

### Modelos de Linguagem (Embeddings)
* **Estat√≠sticos/Baselines:** TF-IDF.
* **Est√°ticos:** Word2Vec, GloVe, FastText.
* **Contextuais (Transformers):** BERT (Multilingual Cased).
* **LLMs & APIs Modernas:**
    * OpenAI (`text-embedding-3-small`)
    * Google Gemini
    * SFR-Embedding-Mistral
    * Jina-Embeddings-v2
    * KALM, Serafim, E5.

### Bibliotecas Principais
* `scikit-learn`: Para classificadores e m√©tricas.
* `transformers` (Hugging Face): Para modelos BERT e locais.
* `gensim`: Para Word2Vec e FastText.
* `pandas` & `numpy`: Manipula√ß√£o de dados.
* `nltk` & `spacy`: Pr√©-processamento.

## üìä Metodologia

O fluxo de trabalho (Pipeline) seguiu as seguintes etapas rigorosas:

1.  **Dataset:** Utiliza√ß√£o do corpus **Fake.br-Corpus**, contendo 7.200 not√≠cias (3.600 verdadeiras e 3.600 falsas), perfeitamente balanceado.
2.  **Pr√©-processamento:**
    * Limpeza de caracteres especiais.
    * Remo√ß√£o de *stopwords* (testado com e sem).
    * Lemmatiza√ß√£o.
3.  **Feature Extraction:** Gera√ß√£o de embeddings utilizando os modelos citados acima. Foram testadas combina√ß√µes de entrada: *Apenas T√≠tulo*, *Apenas Texto*, e *Completo (T√≠tulo + Subt√≠tulo + Texto)*.
4.  **Classifica√ß√£o:** Treinamento supervisionado utilizando valida√ß√£o cruzada.
5.  **Otimiza√ß√£o:** Uso de *Grid Search* e *Random Search* para refinar os hiperpar√¢metros.

## üèÜ Resultados Principais

Os resultados demonstraram que, embora os LLMs sejam poderosos, t√©cnicas cl√°ssicas bem ajustadas ainda s√£o extremamente competitivas para esta tarefa espec√≠fica.

Abaixo, os **Top 5 Melhores Resultados** (ordenados por F1-Score no conjunto de teste):

| Modelo de Embedding | Classificador | Acur√°cia | F1-Score | Detalhes |
| :--- | :--- | :--- | :--- | :--- |
| **OpenAI (3-small)** | Logistic Regression | **98.32%** | **0.9832** | Otimizado (RandomSearch) |
| **TF-IDF** | SVM | 97.98% | 0.9798 | Otimizado (GridSearch) |
| **TF-IDF** | Logistic Regression | 97.82% | 0.9782 | Otimizado (GridSearch) |
| **SFR-Mistral** | SVM | 97.27% | 0.9727 | Configura√ß√£o Base |
| **BERT** | Logistic Regression | 96.72% | 0.9672 | Configura√ß√£o Base |

> **Insight:** O modelo da OpenAI obteve o melhor desempenho global, mas o **TF-IDF** (uma t√©cnica muito mais leve e r√°pida) ficou tecnicamente empatado, provando ser uma solu√ß√£o eficiente e de baixo custo computacional para detec√ß√£o de fake news neste corpus.

### An√°lise por Combina√ß√£o de Texto
A utiliza√ß√£o do **conte√∫do completo** (T√≠tulo + Subt√≠tulo + Texto) provou ser consistentemente superior ao uso isolado de apenas t√≠tulos ou apenas corpo do texto.

## üöÄ Como Executar

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/SEU_USUARIO/NOME_DO_REPO.git](https://github.com/SEU_USUARIO/NOME_DO_REPO.git)
    cd NOME_DO_REPO
    ```

2.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Estrutura de Arquivos:**
    * `/notebooks`: Jupyter Notebooks com os experimentos de cada modelo.
    * `/data`: Amostras do dataset (ou instru√ß√µes para baixar o Fake.br-Corpus original).
    * `/results`: Arquivos CSV com os logs detalhados de todas as execu√ß√µes.
    * `/src`: Scripts auxiliares de pr√©-processamento.

## üîó Refer√™ncias

* *Monteiro, R. A., et al. (2018). "Fake.br-corpus: A fake news dataset in portuguese."*
* *Vaswani, A., et al. (2017). "Attention is all you need."*

---
Desenvolvido por **Ot√°vio Augusto Teixeira** como requisito para obten√ß√£o do t√≠tulo de Bacharel em Ci√™ncia da Computa√ß√£o.